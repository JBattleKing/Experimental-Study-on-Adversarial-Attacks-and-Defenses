{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "classification_task = pipeline(\"sentiment-analysis\",model = \"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string \n",
    "result = string.punctuation \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "model = SentenceTransformer('stsb-roberta-large')\n",
    "from tabulate import tabulate\n",
    "import ipysheet\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import homoglyphs as hg\n",
    "from itertools import combinations\n",
    "pyTorchData = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "bertAttackData = pd.read_csv('https://raw.githubusercontent.com/LinyangLee/BERT-Attack/master/data_defense/imdb_1k.tsv', delimiter='\\t', header=None)\n",
    "batch1=pyTorchData[0:10]\n",
    "sentences = batch1[0]#here we can easily add the adversarial sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homoglyphAttack(word):\n",
    "    listed = list(word)\n",
    "    changes = []\n",
    "    for j in range(len(listed)):\n",
    "        possible = hg.Homoglyphs().get_combinations(listed[j])\n",
    "        for k in possible:\n",
    "            listed[j]=k\n",
    "            changes.append(\"\".join(listed))\n",
    "        listed = list(word)\n",
    "    return(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charAttack(sentence,attack):\n",
    "    if attack==\"swap\":\n",
    "        everything = {}\n",
    "        sentences = sentence\n",
    "        sentences = sentences.replace(\". \",\".. \")\n",
    "        sentences = sentences.replace(\"? \",\"?. \")\n",
    "        sentences = sentences.replace(\"; \",\";. \")\n",
    "        sentences = sentences.replace(\"! \",\"!. \")\n",
    "        sentenceList = sentences.split(\". \")\n",
    "        for z in range(len(sentenceList)):\n",
    "            tempStorage = []\n",
    "            originalSentence = sentenceList[z]\n",
    "            originalLabel = classification_task(originalSentence)[0][\"label\"]#Get og sentence label\n",
    "            originalScore = classification_task(originalSentence)[0][\"score\"]#get og sentence confidence\n",
    "            originalEmbedding = model.encode(originalSentence, convert_to_tensor=True)#get vector of og sentence\n",
    "            b = originalSentence#get another variable of the og sentence so when i change the og sentence punctuation i can revert it\n",
    "            for k in originalSentence:#goes through all the characters of the og sentence\n",
    "                if k in result:#if the character is a punctuation character then it is replaced with the same punctuation but surrounded by spaces\n",
    "                    originalSentence = originalSentence.replace(k,\" \"+k+\" \")#the spaces are included so BERT knows that it is separate and is easier to split\n",
    "            listed = originalSentence.split()#split the og sentence into a list. split by spaces \n",
    "            #initialize some lists\n",
    "            different = []#one for when the label is different\n",
    "            same = []#when the label is the same\n",
    "            stopWords = []#used to house all the stop words\n",
    "            a = False#used in case all words are stop words\n",
    "            for i in range(len(listed)):#goes through all the words in the list\n",
    "                if listed[i] not in stops:#if the word is not a stop word\n",
    "                    listed = originalSentence.split()#make the list back into the og so this loop can run again\n",
    "                    swappedWords = swapChar(listed[i])\n",
    "                    for k in swappedWords:\n",
    "                        changedWord = k\n",
    "                        listed[i]=k\n",
    "                        saved = ' '.join(listed)\n",
    "                        changedSentence = saved#gets the changed sentence\n",
    "                        changedLabel = classification_task(changedSentence)[0][\"label\"]#gets changed sentence label\n",
    "                        changedScore = classification_task(changedSentence)[0][\"score\"]#gets changed sentence confidence level\n",
    "                        changedEmbedding = model.encode(changedSentence, convert_to_tensor=True)#gets vector of the changed sentence\n",
    "                        cosine_scores = util.pytorch_cos_sim(originalEmbedding, changedEmbedding)#gets the cosine score of the two vectors\n",
    "                        #basically gets the similarity score of the two sentences\n",
    "                        if changedLabel != originalLabel:#if the changed sentence label is different from the og label\n",
    "                            #append it and all its information into a list of just when the label is different\n",
    "                            different.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "\n",
    "                        else:\n",
    "                            #appends all the information when the label is the same\n",
    "                            same.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "                    saved = ''#restart the variables so the loop can run again\n",
    "                    a=True#just meant to signify there is at least one example where there is information in the loops\n",
    "                else:#if the word is a stop word\n",
    "                    stopWords.append(listed[i])#append just that word into a list of just stop words\n",
    "            if(a):#only run this portion if info in the lists exist\n",
    "\n",
    "                if len(different)==0 and len(same)!=0:#if there are no instances of different labels\n",
    "                    #initialize the info\n",
    "                    minScore = same[0][2]\n",
    "                    minSentence = same[0][0]\n",
    "                    minWord = same[0][4]\n",
    "                    minLabel = same[0][1]\n",
    "                    minCosine = same[0][3]\n",
    "                    simWord = same[0][4]\n",
    "                    simScore = same[0][2]\n",
    "                    simSentence = same[0][0]\n",
    "                    simLabel = same[0][1]\n",
    "                    simCosine = same[0][3]\n",
    "                    for j in range(len(same)):\n",
    "                        if same[j][3]>simCosine:#if there is a sentence with a higher similarity rating\n",
    "                            #that its information\n",
    "                            simScore = same[j][2]\n",
    "                            simSentence = same[j][0]\n",
    "                            simLabel = same[j][1]\n",
    "                            simCosine = same[j][3]\n",
    "                            simWord = same[j][4]\n",
    "                            #then just print the info out\n",
    "                        if minScore>same[j][2]:\n",
    "                            minScore = same[j][2]\n",
    "                            minSentence = same[j][0]\n",
    "                            minLabel = same[j][1]\n",
    "                            minCosine = same[j][3]\n",
    "                            minWord = same[j][4]\n",
    "                    \n",
    "                    tempStorage.append(minSentence)\n",
    "                    tempStorage.append(minWord)\n",
    "                    tempStorage.append(minCosine)\n",
    "                    \n",
    "                elif len(different)!=0:#if there is atleast one sentence that has a different label\n",
    "                    #initialize the info\n",
    "                    maxScore = different[0][2]\n",
    "                    maxSentence = different[0][0]\n",
    "                    maxLabel = different[0][1]\n",
    "                    maxCosine = different[0][3]\n",
    "                    maxWord = different[0][4]\n",
    "                    simSentence = different[0][0]\n",
    "                    simScore = different[0][2]\n",
    "                    simSentence = different[0][0]\n",
    "                    simLabel = different[0][1]\n",
    "                    simCosine = different[0][3]\n",
    "                    simWord = different[0][4]\n",
    "                    for j in range(len(different)):#goes through all the different label sentences\n",
    "                        if different[j][3]>simCosine:#if its similarity score is higher\n",
    "                            #take its information\n",
    "                            simScore = different[j][2]\n",
    "                            simSentence = different[j][0]\n",
    "                            simLabel = different[j][1]\n",
    "                            simCosine = different[j][3]\n",
    "                            simWord = different[j][4]\n",
    "                        if maxScore<different[j][2]:\n",
    "                            maxScore = different[j][2]\n",
    "                            maxSentence = different[j][0]\n",
    "                            maxLabel = different[j][1]\n",
    "                            maxCosine = different[j][3]   \n",
    "                            maxWord = different[j][4]\n",
    "                    #print all that info out\n",
    "                    \n",
    "                    tempStorage.append(maxSentence)\n",
    "                    tempStorage.append(maxWord)\n",
    "                    tempStorage.append(maxCosine)\n",
    "            \n",
    "            everything[z]=tempStorage  \n",
    "    if attack==\"homoglyph\":\n",
    "        everything = {}\n",
    "        sentences = sentence\n",
    "        sentences = sentences.replace(\". \",\".. \")\n",
    "        sentences = sentences.replace(\"? \",\"?. \")\n",
    "        sentences = sentences.replace(\"; \",\";. \")\n",
    "        sentences = sentences.replace(\"! \",\"!. \")\n",
    "        sentenceList = sentences.split(\". \")\n",
    "        for z in range(len(sentenceList)):\n",
    "            tempStorage = []\n",
    "            originalSentence = sentenceList[z]\n",
    "            originalLabel = classification_task(originalSentence)[0][\"label\"]#Get og sentence label\n",
    "            originalScore = classification_task(originalSentence)[0][\"score\"]#get og sentence confidence\n",
    "            originalEmbedding = model.encode(originalSentence, convert_to_tensor=True)#get vector of og sentence\n",
    "            b = originalSentence#get another variable of the og sentence so when i change the og sentence punctuation i can revert it\n",
    "            for k in originalSentence:#goes through all the characters of the og sentence\n",
    "                if k in result:#if the character is a punctuation character then it is replaced with the same punctuation but surrounded by spaces\n",
    "                    originalSentence = originalSentence.replace(k,\" \"+k+\" \")#the spaces are included so BERT knows that it is separate and is easier to split\n",
    "            listed = originalSentence.split()#split the og sentence into a list. split by spaces \n",
    "            #initialize some lists\n",
    "            different = []#one for when the label is different\n",
    "            same = []#when the label is the same\n",
    "            stopWords = []#used to house all the stop words\n",
    "            a = False#used in case all words are stop words\n",
    "            for i in range(len(listed)):#goes through all the words in the list\n",
    "                if listed[i] not in stops:#if the word is not a stop word\n",
    "                    listed = originalSentence.split()#make the list back into the og so this loop can run again\n",
    "                    swappedWords = homoglyphAttack(listed[i])\n",
    "                    for k in swappedWords:\n",
    "                        changedWord = k\n",
    "                        listed[i]=k\n",
    "                        saved = ' '.join(listed)\n",
    "                        changedSentence = saved#gets the changed sentence\n",
    "                        changedLabel = classification_task(changedSentence)[0][\"label\"]#gets changed sentence label\n",
    "                        changedScore = classification_task(changedSentence)[0][\"score\"]#gets changed sentence confidence level\n",
    "                        changedEmbedding = model.encode(changedSentence, convert_to_tensor=True)#gets vector of the changed sentence\n",
    "                        cosine_scores = util.pytorch_cos_sim(originalEmbedding, changedEmbedding)#gets the cosine score of the two vectors\n",
    "                        #basically gets the similarity score of the two sentences\n",
    "                        if changedLabel != originalLabel:#if the changed sentence label is different from the og label\n",
    "                            #append it and all its information into a list of just when the label is different\n",
    "                            different.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "\n",
    "                        else:\n",
    "                            #appends all the information when the label is the same\n",
    "                            same.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "                    saved = ''#restart the variables so the loop can run again\n",
    "                    a=True#just meant to signify there is at least one example where there is information in the loops\n",
    "                else:#if the word is a stop word\n",
    "                    stopWords.append(listed[i])#append just that word into a list of just stop words\n",
    "            if(a):#only run this portion if info in the lists exist\n",
    "\n",
    "                if len(different)==0 and len(same)!=0:#if there are no instances of different labels\n",
    "                    #initialize the info\n",
    "                    minScore = same[0][2]\n",
    "                    minSentence = same[0][0]\n",
    "                    minWord = same[0][4]\n",
    "                    minLabel = same[0][1]\n",
    "                    minCosine = same[0][3]\n",
    "                    simWord = same[0][4]\n",
    "                    simScore = same[0][2]\n",
    "                    simSentence = same[0][0]\n",
    "                    simLabel = same[0][1]\n",
    "                    simCosine = same[0][3]\n",
    "                    for j in range(len(same)):\n",
    "                        if same[j][3]>simCosine:#if there is a sentence with a higher similarity rating\n",
    "                            #that its information\n",
    "                            simScore = same[j][2]\n",
    "                            simSentence = same[j][0]\n",
    "                            simLabel = same[j][1]\n",
    "                            simCosine = same[j][3]\n",
    "                            simWord = same[j][4]\n",
    "                            #then just print the info out\n",
    "                        if minScore>same[j][2]:\n",
    "                            minScore = same[j][2]\n",
    "                            minSentence = same[j][0]\n",
    "                            minLabel = same[j][1]\n",
    "                            minCosine = same[j][3]\n",
    "                            minWord = same[j][4]\n",
    "                    \n",
    "                    tempStorage.append(minSentence)\n",
    "                    tempStorage.append(minWord)\n",
    "                    tempStorage.append(minCosine)\n",
    "                elif len(different)!=0:#if there is atleast one sentence that has a different label\n",
    "                    #initialize the info\n",
    "                    maxScore = different[0][2]\n",
    "                    maxSentence = different[0][0]\n",
    "                    maxLabel = different[0][1]\n",
    "                    maxCosine = different[0][3]\n",
    "                    maxWord = different[0][4]\n",
    "                    simSentence = different[0][0]\n",
    "                    simScore = different[0][2]\n",
    "                    simSentence = different[0][0]\n",
    "                    simLabel = different[0][1]\n",
    "                    simCosine = different[0][3]\n",
    "                    simWord = different[0][4]\n",
    "                    for j in range(len(different)):#goes through all the different label sentences\n",
    "                        if different[j][3]>simCosine:#if its similarity score is higher\n",
    "                            #take its information\n",
    "                            simScore = different[j][2]\n",
    "                            simSentence = different[j][0]\n",
    "                            simLabel = different[j][1]\n",
    "                            simCosine = different[j][3]\n",
    "                            simWord = different[j][4]\n",
    "                        if maxScore<different[j][2]:\n",
    "                            maxScore = different[j][2]\n",
    "                            maxSentence = different[j][0]\n",
    "                            maxLabel = different[j][1]\n",
    "                            maxCosine = different[j][3]   \n",
    "                            maxWord = different[j][4]\n",
    "                    #print all that info out\n",
    "                    \n",
    "                    tempStorage.append(maxSentence)\n",
    "                    tempStorage.append(maxWord)\n",
    "                    tempStorage.append(maxCosine)\n",
    "            everything[z]=tempStorage  \n",
    "    if attack==\"delete\":\n",
    "        everything = {}\n",
    "        sentences = sentence\n",
    "        sentences = sentences.replace(\". \",\".. \")\n",
    "        sentences = sentences.replace(\"? \",\"?. \")\n",
    "        sentences = sentences.replace(\"; \",\";. \")\n",
    "        sentences = sentences.replace(\"! \",\"!. \")\n",
    "        sentenceList = sentences.split(\". \")\n",
    "        for z in range(len(sentenceList)):\n",
    "            tempStorage = []\n",
    "            originalSentence = sentenceList[z]\n",
    "            originalLabel = classification_task(originalSentence)[0][\"label\"]#Get og sentence label\n",
    "            originalScore = classification_task(originalSentence)[0][\"score\"]#get og sentence confidence\n",
    "            originalEmbedding = model.encode(originalSentence, convert_to_tensor=True)#get vector of og sentence\n",
    "            b = originalSentence#get another variable of the og sentence so when i change the og sentence punctuation i can revert it\n",
    "            for k in originalSentence:#goes through all the characters of the og sentence\n",
    "                if k in result:#if the character is a punctuation character then it is replaced with the same punctuation but surrounded by spaces\n",
    "                    originalSentence = originalSentence.replace(k,\" \"+k+\" \")#the spaces are included so BERT knows that it is separate and is easier to split\n",
    "            listed = originalSentence.split()#split the og sentence into a list. split by spaces \n",
    "            #initialize some lists\n",
    "            different = []#one for when the label is different\n",
    "            same = []#when the label is the same\n",
    "            stopWords = []#used to house all the stop words\n",
    "            a = False#used in case all words are stop words\n",
    "            for i in range(len(listed)):#goes through all the words in the list\n",
    "                if listed[i] not in stops:#if the word is not a stop word\n",
    "                    listed = originalSentence.split()#make the list back into the og so this loop can run again\n",
    "                    swappedWords = deleteAttack(listed[i])\n",
    "                    for k in swappedWords:\n",
    "                        changedWord = k\n",
    "                        listed[i]=k\n",
    "                        saved = ' '.join(listed)\n",
    "                        changedSentence = saved#gets the changed sentence\n",
    "                        changedLabel = classification_task(changedSentence)[0][\"label\"]#gets changed sentence label\n",
    "                        changedScore = classification_task(changedSentence)[0][\"score\"]#gets changed sentence confidence level\n",
    "                        changedEmbedding = model.encode(changedSentence, convert_to_tensor=True)#gets vector of the changed sentence\n",
    "                        cosine_scores = util.pytorch_cos_sim(originalEmbedding, changedEmbedding)#gets the cosine score of the two vectors\n",
    "                        #basically gets the similarity score of the two sentences\n",
    "                        if changedLabel != originalLabel:#if the changed sentence label is different from the og label\n",
    "                            #append it and all its information into a list of just when the label is different\n",
    "                            different.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "\n",
    "                        else:\n",
    "                            #appends all the information when the label is the same\n",
    "                            same.append([changedSentence,changedLabel,changedScore,cosine_scores.item(),changedWord])\n",
    "                    saved = ''#restart the variables so the loop can run again\n",
    "                    a=True#just meant to signify there is at least one example where there is information in the loops\n",
    "                else:#if the word is a stop word\n",
    "                    stopWords.append(listed[i])#append just that word into a list of just stop words\n",
    "            if(a):#only run this portion if info in the lists exist\n",
    "\n",
    "                if len(different)==0 and len(same)!=0:#if there are no instances of different labels\n",
    "                    #initialize the info\n",
    "                    minScore = same[0][2]\n",
    "                    minSentence = same[0][0]\n",
    "                    minWord = same[0][4]\n",
    "                    minLabel = same[0][1]\n",
    "                    minCosine = same[0][3]\n",
    "                    simWord = same[0][4]\n",
    "                    simScore = same[0][2]\n",
    "                    simSentence = same[0][0]\n",
    "                    simLabel = same[0][1]\n",
    "                    simCosine = same[0][3]\n",
    "                    for j in range(len(same)):\n",
    "                        if same[j][3]>simCosine:#if there is a sentence with a higher similarity rating\n",
    "                            #that its information\n",
    "                            simScore = same[j][2]\n",
    "                            simSentence = same[j][0]\n",
    "                            simLabel = same[j][1]\n",
    "                            simCosine = same[j][3]\n",
    "                            simWord = same[j][4]\n",
    "                            #then just print the info out\n",
    "                        if minScore>same[j][2]:\n",
    "                            minScore = same[j][2]\n",
    "                            minSentence = same[j][0]\n",
    "                            minLabel = same[j][1]\n",
    "                            minCosine = same[j][3]\n",
    "                            minWord = same[j][4]\n",
    "                    \n",
    "                    tempStorage.append(minSentence)\n",
    "                    tempStorage.append(minWord)\n",
    "                    tempStorage.append(minCosine)\n",
    "                elif len(different)!=0:#if there is atleast one sentence that has a different label\n",
    "                    #initialize the info\n",
    "                    maxScore = different[0][2]\n",
    "                    maxSentence = different[0][0]\n",
    "                    maxLabel = different[0][1]\n",
    "                    maxCosine = different[0][3]\n",
    "                    maxWord = different[0][4]\n",
    "                    simSentence = different[0][0]\n",
    "                    simScore = different[0][2]\n",
    "                    simSentence = different[0][0]\n",
    "                    simLabel = different[0][1]\n",
    "                    simCosine = different[0][3]\n",
    "                    simWord = different[0][4]\n",
    "                    for j in range(len(different)):#goes through all the different label sentences\n",
    "                        if different[j][3]>simCosine:#if its similarity score is higher\n",
    "                            #take its information\n",
    "                            simScore = different[j][2]\n",
    "                            simSentence = different[j][0]\n",
    "                            simLabel = different[j][1]\n",
    "                            simCosine = different[j][3]\n",
    "                            simWord = different[j][4]\n",
    "                        if maxScore<different[j][2]:\n",
    "                            maxScore = different[j][2]\n",
    "                            maxSentence = different[j][0]\n",
    "                            maxLabel = different[j][1]\n",
    "                            maxCosine = different[j][3]   \n",
    "                            maxWord = different[j][4]\n",
    "                    #print all that info out\n",
    "                    \n",
    "                    tempStorage.append(maxSentence)\n",
    "                    tempStorage.append(maxWord)\n",
    "                    tempStorage.append(maxCosine)\n",
    "            everything[z]=tempStorage  \n",
    "    if(not a):\n",
    "        everything[0]=[sentence,\"\",0]\n",
    "    return everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run this if you want adversarial example\n",
    "adversarialSentences = []\n",
    "changedWords = []\n",
    "cosineScores = []\n",
    "runtimes = []\n",
    "total = 0\n",
    "counter = 0\n",
    "for i in batch1[0]:\n",
    "    start = timer()\n",
    "    a=charAttack(i,\"homoglyph\")\n",
    "    end = timer()\n",
    "    runtimes.append(end-start)\n",
    "    total+=(end-start)\n",
    "    adversarialSentences.append(a[0][0])\n",
    "    changedWords.append(a[0][1])\n",
    "    cosineScores.append(a[0][2])\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "sentences = adversarialSentences\n",
    "allLabels = {}\n",
    "dictClassifications = {}\n",
    "for i in range(len(sentences)):\n",
    "    a = classification_task(sentences[i])\n",
    "    dictClassifications[i]=a,sentences[i],batch1[1][i]\n",
    "for i in dictClassifications:\n",
    "    correct = False\n",
    "    if dictClassifications[i][0][0][\"label\"] == \"POSITIVE\":\n",
    "        predictedLabel = 1\n",
    "    else:\n",
    "        predictedLabel = 0\n",
    "    givenLabel = dictClassifications[i][-1]\n",
    "    if predictedLabel==givenLabel:\n",
    "        correct = True\n",
    "    allLabels[i]=sentences[i],dictClassifications[i][0],predictedLabel,givenLabel,correct,changedWords[i],cosineScores[i],runtimes[i]\n",
    "    \n",
    "totalWrong = 0\n",
    "wrongSentences = []\n",
    "for i in allLabels:\n",
    "    correct = allLabels[i][-2]\n",
    "    if not correct:\n",
    "        wrongLabel = allLabels[i][1][0][\"label\"]\n",
    "        wrongConfidence = allLabels[i][1][0][\"score\"]\n",
    "        wrongSentences.append((sentences[i],wrongLabel,wrongConfidence,i))\n",
    "        \n",
    "        totalWrong+=1\n",
    "percentageRight = (len(allLabels)-totalWrong)/len(allLabels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Sentence\", \"Actual Label\",\"Predicted Label\",\"Confidence\",\"Accuracy\",\"Changed Word\",\"Cosine Similarity Score\",\"Runtimes(s)\"]\n",
    "data = []\n",
    "for i in range(len(allLabels)):\n",
    "    sentence = allLabels[i][0]\n",
    "    changedWord = allLabels[i][5]\n",
    "    confidence = allLabels[i][1][0]['score']\n",
    "    similarity = allLabels[i][6]\n",
    "    runtime = allLabels[i][7]\n",
    "    if allLabels[i][2]==1:\n",
    "        predicted = 'Positive'\n",
    "    elif allLabels[i][2]==0:\n",
    "        predicted = 'Negative'\n",
    "    if allLabels[i][3]==1:\n",
    "        actual = 'Positive'\n",
    "    elif allLabels[i][3]==0:\n",
    "        actual = 'Negative'\n",
    "    if allLabels[i][4]:\n",
    "        correct = \"Correct\"\n",
    "    else:\n",
    "        correct = \"False\"\n",
    "    data.append([sentence,actual,predicted,confidence,correct,changedWord,similarity,runtime])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositives = []\n",
    "trueNegatives = []\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "for i in range(len(data)):\n",
    "    if data[i][4]==\"False\":\n",
    "        if data[i][2]=='Positive':\n",
    "            falsePositives.append(i)\n",
    "        else:\n",
    "            falseNegatives.append(i)\n",
    "    else:\n",
    "        if data[i][2]=='Positive':\n",
    "            truePositives.append(i)\n",
    "        else:\n",
    "            trueNegatives.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTruePositives = len(truePositives)\n",
    "numTrueNegatives = len(trueNegatives)\n",
    "numFalsePositives = len(falsePositives)\n",
    "numFalseNegatives = len(falseNegatives)\n",
    "accuracy = (numTruePositives+numTrueNegatives)/(numTruePositives+numTrueNegatives+numFalsePositives+numFalseNegatives)\n",
    "precision = numTruePositives/(numTruePositives+numFalsePositives)\n",
    "recall = numTruePositives/(numTruePositives+numFalseNegatives)\n",
    "specificity =numTrueNegatives/(numTrueNegatives+numFalsePositives)\n",
    "f1 = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Adversarial_Char_Homoglyph_PyTorch_VPN.csv\"\n",
    "col_names = [\"Sentence\", \"Actual Label\",\"Predicted Label\",\"Confidence\",\"Accuracy\",\"Changed Word\",\"Cosine Similarity Score\",\"Runtimes(s)\"]\n",
    "row1 = [f\"Accuracy:{accuracy:.3f}\",f\"Precision:{precision:.3f}\",f\"Recall:{recall:.3f}\",f\"Specificity:{specificity:.3f}\",f\"F1-Score:{f1:.3f}\",f\"Total Runtime(s):{total:.3f}\"]\n",
    "with open(filename, 'w') as csvfile:\n",
    "    # creating a csv writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "     \n",
    "    # writing the fields\n",
    "    csvwriter.writerow(row1)\n",
    "    csvwriter.writerow(col_names)\n",
    "     \n",
    "    # writing the data rows\n",
    "    csvwriter.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
