{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jonathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "classification_task = pipeline(\"sentiment-analysis\",model = \"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "import string \n",
    "result = string.punctuation \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "model = SentenceTransformer('stsb-roberta-large')\n",
    "from tabulate import tabulate\n",
    "import ipysheet\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "import homoglyphs as hg\n",
    "from itertools import combinations\n",
    "pyTorchData = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "bertAttackData = pd.read_csv('https://raw.githubusercontent.com/LinyangLee/BERT-Attack/master/data_defense/imdb_1k.tsv', delimiter='\\t', header=None)\n",
    "batch1=pyTorchData[0:5000]\n",
    "sentences = batch1[0]#here we can easily add the adversarial sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for regular\n",
    "allLabels = {}\n",
    "dictClassifications = {}\n",
    "totalTime = 0\n",
    "for i in range(len(sentences)):\n",
    "    start = timer()\n",
    "    a = classification_task(sentences[i])\n",
    "    end=timer()\n",
    "    totalTime+=(end-start)\n",
    "    dictClassifications[i]=a,sentences[i],batch1[1][i],(end-start)\n",
    "for i in dictClassifications:\n",
    "    correct = False\n",
    "    if dictClassifications[i][0][0][\"label\"] == \"POSITIVE\":\n",
    "        predictedLabel = 1\n",
    "    else:\n",
    "        predictedLabel = 0\n",
    "    givenLabel = dictClassifications[i][2]\n",
    "    if predictedLabel==givenLabel:\n",
    "        correct = True\n",
    "    allLabels[i]=sentences[i],dictClassifications[i][0],predictedLabel,givenLabel,correct,dictClassifications[i][3]\n",
    "totalWrong = 0\n",
    "wrongSentences = []\n",
    "for i in allLabels:\n",
    "    correct = allLabels[i][-1]\n",
    "    if not correct:\n",
    "        wrongLabel = allLabels[i][1][0][\"label\"]\n",
    "        wrongConfidence = allLabels[i][1][0][\"score\"]\n",
    "        wrongSentences.append((sentences[i],wrongLabel,wrongConfidence,i))\n",
    "        \n",
    "        totalWrong+=1\n",
    "percentageRight = (len(allLabels)-totalWrong)/len(allLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Sentence\", \"Actual Label\",\"Predicted Label\",\"Confidence\",\"Accuracy\",\"Runtime\"]\n",
    "data = []\n",
    "for i in range(len(allLabels)):\n",
    "    sentence = allLabels[i][0]\n",
    "    confidence = allLabels[i][1][0]['score']\n",
    "    runtime = allLabels[i][5]\n",
    "    if allLabels[i][2]==1:\n",
    "        predicted = 'Positive'\n",
    "    elif allLabels[i][2]==0:\n",
    "        predicted = 'Negative'\n",
    "    if allLabels[i][3]==1:\n",
    "        actual = 'Positive'\n",
    "    elif allLabels[i][3]==0:\n",
    "        actual = 'Negative'\n",
    "    if allLabels[i][4]:\n",
    "        correct = \"Correct\"\n",
    "    else:\n",
    "        correct = \"False\"\n",
    "    data.append([sentence,actual,predicted,confidence,correct,runtime])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositives = []\n",
    "trueNegatives = []\n",
    "falsePositives = []\n",
    "falseNegatives = []\n",
    "for i in range(len(data)):\n",
    "    if data[i][4]==\"False\":\n",
    "        if data[i][2]=='Positive':\n",
    "            falsePositives.append(i)\n",
    "        else:\n",
    "            falseNegatives.append(i)\n",
    "    else:\n",
    "        if data[i][2]=='Positive':\n",
    "            truePositives.append(i)\n",
    "        else:\n",
    "            trueNegatives.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTruePositives = len(truePositives)\n",
    "numTrueNegatives = len(trueNegatives)\n",
    "numFalsePositives = len(falsePositives)\n",
    "numFalseNegatives = len(falseNegatives)\n",
    "accuracy = (numTruePositives+numTrueNegatives)/(numTruePositives+numTrueNegatives+numFalsePositives+numFalseNegatives)\n",
    "precision = numTruePositives/(numTruePositives+numFalsePositives)\n",
    "recall = numTruePositives/(numTruePositives+numFalseNegatives)\n",
    "specificity =numTrueNegatives/(numTrueNegatives+numFalsePositives)\n",
    "f1 = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Original_PyTorch_VPN.csv\"#NEED TO CHANGE IF DIFF DATASET\n",
    "col_names = [\"Sentence\", \"Actual Label\",\"Predicted Label\",\"Confidence\",\"Accuracy\",\"Changed Word\",\"Runtime\"]\n",
    "row1 = [f\"Accuracy:{accuracy:.3f}\",f\"Precision:{precision:.3f}\",f\"Recall:{recall:.3f}\",f\"Specificity:{specificity:.3f}\",f\"F1-Score:{f1:.3f}\",f\"Total Runtime:{totalTime:.3f}\"]\n",
    "with open(filename, 'w') as csvfile:\n",
    "    # creating a csv writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "     \n",
    "    # writing the fields\n",
    "    csvwriter.writerow(row1)\n",
    "    csvwriter.writerow(col_names)\n",
    "     \n",
    "    # writing the data rows\n",
    "    csvwriter.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
